---
sidebar: sidebar 
permalink: requirements.html 
keywords: ai, chatbot, prerequisites, bedrock, fsx for ontap, prerequisites, requirements 
summary: ナレッジベースを構築する前に、Workload FactoryとAWSが正しく設定されていることを確認してください。これには、AWSのログインクレデンシャル、ナレッジベースに統合するデータソースを含む導入済みのFSx for ONTAPファイルシステム、Amazon Bedrock AIサービスへのアクセスなどが含まれます。 
---
= GenAIの要件
:allow-uri-read: 
:icons: font
:imagesdir: ./media/


[role="lead"]
ナレッジベースを構築する前に、Workload FactoryとAWSが正しく設定されていることを確認してください。これには、AWSのログインクレデンシャル、ナレッジベースに統合するデータソースを含む導入済みのFSx for ONTAPファイルシステム、Amazon Bedrock AIサービスへのアクセスなどが含まれます。

Workload Factoryのログインとアカウント:: Workload Factoryにログインし、アカウントを作成する必要があります。
+
--
https://docs.netapp.com/us-en/workload-setup-admin/sign-up-saas.html["ログインとアカウントの作成の詳細"^]

--
AWS のクレデンシャルと権限:: AWSクレデンシャルをWorkload Factoryに自動化権限で追加する必要があります。つまり、GenAIのWorkload Factoryを_automate_modeで使用することになります。
+
--
現時点では、_basic_modeおよび_read_mode権限はサポートされていません。

クレデンシャルを設定する際に、以下に示すように権限を選択すると、FSx for ONTAPファイルシステムの管理、GenAI EC2インスタンスおよびナレッジベースとチャットボットに必要なその他のAWSリソースの導入と管理を行うためのフルアクセスが提供されます。

image:screenshot-ai-permissions.png["AIリソースを完全に管理するための権限設定を示すスクリーンショット。"]

https://docs.netapp.com/us-en/workload-setup-admin/add-credentials.html["AWSクレデンシャルをWorkload Factoryに追加する方法"^]

--
Amazon Bedrock:: Amazon Bedrockを使用すると、基盤モデルを使用でき、生成型AIアプリケーションを構築するための機能を提供します。
+
--
Workload Factory for GenAIを始める前に、Amazon Bedrockをセットアップする必要があります。GenAI環境は、Amazon Bedrockが有効になっているAWSリージョンに配置する必要があります。

* https://docs.aws.amazon.com/bedrock/latest/userguide/setting-up.html["AWSのドキュメント：Amazon Bedrockのセットアップ"^]
* https://docs.aws.amazon.com/bedrock/latest/userguide/knowledge-base-supported.html["AWSのドキュメント：Amazon Bedrockのナレッジベースでサポートされるリージョンとモデル"^]


--
埋め込みモデル:: ナレッジベースを作成する前に、使用する予定の埋め込みモデルを有効にする必要があります。次の埋め込みモデルがサポートされています。
+
--
* Titan埋め込みG1 -テキスト
* Titan埋め込みテキストv2
* Titan Multimodal Embedding G1
+
https://aws.amazon.com/bedrock/titan/["Amazon Titanの詳細"^]



--
チャットモデル:: ナレッジベースを作成する前に、使用する予定の基本チャットモデルを有効にする必要があります。次のClaudeチャットモデルがサポートされています。
+
--
* クロード3.5ソネット
* クロード3オプス
* クロード3ハイク"
* クロード3ソネット
* クロード2.1
* クロード2.0
+
サポートされるモデルはAWSのリージョンによって異なるため、ナレッジベースを導入するリージョンで使用できるモデルを確認するには、を参照し https://docs.aws.amazon.com/bedrock/latest/userguide/models-regions.html["AWSのドキュメントページ"^] てください。

+
選択に役立つ利用可能なモデルの詳細については、以下を参照してください。 https://aws.amazon.com/bedrock/claude/["Amazon BedrockのAnthropic's Claude"^]



--
FSx for ONTAPファイルシステム:: 少なくとも1つのFSx for ONTAPファイルシステムが必要です。
+
--
* NetApp GenAIエンジンは、ナレッジベースで使用されるベクターデータベースを格納するために1つのファイルシステムを使用します。
+
このFSx for ONTAPファイルシステムでは、FlexVolボリュームを使用する必要があります。FlexGroupボリュームはサポートされません。

* 1つ以上のファイルシステムには、ナレッジベースに統合するデータソースが含まれています。
+
1つのFSx for ONTAPファイルシステムを両方の目的に使用することも、複数のFSx for ONTAPファイルシステムを使用することもできます。

* AWS FSx for ONTAPファイルシステムが配置されているAWSリージョン、VPC、サブネットを把握しておく必要があります。ファイルシステムがAmazon Bedrockが有効になっているAWSリージョンにある必要があります。
* この導入に含まれるAWSリソースに適用するタグのキーと値のペアを検討する必要があります（オプション）。
* NetApp AIエンジンインスタンスに安全に接続するためのキーペア情報を知っておく必要があります。


https://docs.netapp.com/us-en/workload-fsx-ontap/create-file-system.html["FSx for ONTAPファイルシステムの導入と管理の方法をご確認ください"^]

--

