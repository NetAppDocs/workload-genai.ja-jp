---
sidebar: sidebar 
permalink: knowledge-base/requirements-knowledge-base.html 
keywords: ai, chatbot, prerequisites, bedrock, fsx for ontap, prerequisites, requirements 
summary: ナレッジベースを構築する前に、ワークロードファクトリとAWSが適切に設定されていることを確認してください。これには、AWSのログインクレデンシャル、ナレッジベースに統合するデータソースを含む導入済みのFSx for ONTAPファイルシステム、Amazon Bedrock AIサービスへのアクセスなどが含まれます。 
---
= 生成AIナレッジベースの要件
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
ナレッジベースを構築する前に、ワークロードファクトリとAWSが適切に設定されていることを確認してください。これには、AWSのログインクレデンシャル、ナレッジベースに統合するデータソースを含む導入済みのFSx for ONTAPファイルシステム、Amazon Bedrock AIサービスへのアクセスなどが含まれます。



== 生成AIの基本要件

生成AIには、作業を開始する前に環境が満たす必要のある一般的な要件があります。

ワークロードの工場出荷時のログインとアカウント:: のいずれかを使用してログインする https://docs.netapp.com/us-en/workload-setup-admin/console-experiences.html["コンソールエクスペリエンス"^]必要があります https://docs.netapp.com/us-en/workload-setup-admin/sign-up-saas.html["ワークロードファクトリでアカウントを設定する"^]。
AWS のクレデンシャルと権限:: AWSクレデンシャルを読み取り/書き込み権限でWorkload Factoryに追加する必要があります。つまり、生成AIの_読み取り/書き込みモードでWorkload Factoryを使用することになります。
+
--
現時点では、_basic_modeおよび_read-only_mode権限はサポートされていません。

クレデンシャルを設定する際に、以下に示すように権限を選択すると、FSx for ONTAPファイルシステムの管理、GenAI EC2インスタンスおよびナレッジベースとチャットボットに必要なその他のAWSリソースの導入と管理を行うためのフルアクセスが提供されます。

https://docs.netapp.com/us-en/workload-setup-admin/add-credentials.html["ワークロードファクトリにAWSクレデンシャルを追加する方法を確認"^]

--




== 生成AIナレッジベースの要件

ナレッジベースを使用する場合は、環境が次の要件を満たしていることを確認してください。

Amazon Bedrock:: Amazon Bedrockを使用すると、基盤モデルを使用でき、生成型AIアプリケーションを構築するための機能を提供します。
+
--
生成AI用のBlueXP  ワークロードファクトリを開始する前に、Amazon Bedrockをセットアップする必要があります。生成AI環境がAmazon Bedrockが有効になっているAWSリージョンにある必要があります。

* https://docs.aws.amazon.com/bedrock/latest/userguide/setting-up.html["AWSのドキュメント：Amazon Bedrockのセットアップ"^]
* https://docs.aws.amazon.com/bedrock/latest/userguide/knowledge-base-supported.html["AWSのドキュメント：Amazon Bedrockのナレッジベースでサポートされるリージョンとモデル"^]


生成AIは、検索結果の関連性を向上させるために、デフォルトで検索結果を再ランク付けします。最良の結果を得るには、Amazon Bedrock Foundationモデルの構成に、Cohere RerankやAmazon Rerankなどのリランクモデルへのアクセスが含まれていることを確認してください（地域で利用可能な場合）。

--
埋め込みモデル:: ナレッジベースを作成する前に、使用する予定の埋め込みモデルを有効にする必要があります。次の埋め込みモデルがサポートされています。
+
--
* Titan埋め込みG1 -テキスト
* Titan埋め込みテキストv2
* Titan Multimodal Embedding G1
* 英語を埋め込む
* 多言語を埋め込む
+
https://aws.amazon.com/bedrock/titan/["Amazon Titanの詳細"^]



--
チャットモデル:: ナレッジベースを作成する前に、使用する予定の基本チャットモデルを有効にする必要があります。サポートされるモデルはAWSのリージョンによって異なるため、ナレッジベースを導入するリージョンで使用できるモデルを確認するには、を参照し https://docs.aws.amazon.com/bedrock/latest/userguide/models-regions.html["AWSのドキュメント"^] てください。
+
--
生成AIは、Anthropic、Amazon、Mistral AI、Meta、Jamba、Cohereのさまざまなモデルをサポートしています。

Amazon Bedrockでのこれらのモデルの使用について詳しくは、以下をご覧ください。

* https://aws.amazon.com/bedrock/claude/["Amazon BedrockのAnthropic's Claude"^]
* https://docs.aws.amazon.com/nova/latest/userguide/getting-started-console.html["Amazon BedrockコンソールでAmazon Novaを使い始める"^]
* https://aws.amazon.com/bedrock/mistral/["Mistral AIモデル"^]
* https://docs.aws.amazon.com/bedrock/latest/userguide/titan-text-models.html["Amazon Titanテキストモデル"^]
* https://aws.amazon.com/bedrock/llama/["Meta Llamaモデル"^]
* https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-jamba.html["Jambaモデル"^]
* https://aws.amazon.com/bedrock/cohere/["Cohereコマンドモデル"^]


--
FSx for ONTAPファイルシステム:: 少なくとも1つのFSx for ONTAPファイルシステムが必要です。
+
--
* 1つのファイルシステムが、ナレッジベースで使用されるベクターデータベースを格納するために、NetAppの 生成AIエンジンによって使用されます（存在しない場合は作成されます）。
+
このFSx for ONTAPファイルシステムでは、FlexVolボリュームを使用する必要があります。FlexGroupボリュームはサポートされません。

* 1つ以上のファイルシステムには、ナレッジベースに統合するデータソースが含まれています。
+
1つのFSx for ONTAPファイルシステムを両方の目的に使用することも、複数のFSx for ONTAPファイルシステムを使用することもできます。

* AWS FSx for ONTAPファイルシステムが配置されているAWSリージョン、VPC、サブネットを把握しておく必要があります。ファイルシステムがAmazon Bedrockが有効になっているAWSリージョンにある必要があります。
* この導入に含まれるAWSリソースに適用するタグのキーと値のペアを検討する必要があります（オプション）。
* NetApp AIエンジンインスタンスに安全に接続するためのキーペア情報を知っておく必要があります。


https://docs.netapp.com/us-en/workload-fsx-ontap/create-file-system.html["FSx for ONTAPファイルシステムの導入と管理の方法をご確認ください"^]

--

